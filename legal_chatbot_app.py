import os
import streamlit as st
import warnings
import logging

from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_groq import ChatGroq

# =======================
# Secrets (Streamlit Cloud)
# =======================
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    st.error("âŒ GROQ_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets")
    st.stop()

# =======================
# Clean logs
# =======================
warnings.filterwarnings("ignore")
logging.getLogger("pypdf").setLevel(logging.ERROR)
logging.getLogger("langchain").setLevel(logging.ERROR)
logging.getLogger("sentence_transformers").setLevel(logging.ERROR)


# =======================
# Setup
# =======================

PDF_DIR = "laws_pdfs"
os.makedirs(PDF_DIR, exist_ok=True)

# =======================
# Streamlit Config
# =======================
st.set_page_config(page_title="âš–ï¸ Legal AI Assistant", layout="wide")

st.title("âš–ï¸ Legal AI Assistant")
st.caption("Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­Ø§Ù…ÙŠÙ† | LangChain 1.2.7 + Groq")

# =======================
# Sidebar â€“ Upload PDFs
# =======================
st.sidebar.header("ğŸ“¤ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©")

uploaded_files = st.sidebar.file_uploader(
    "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF",
    type=["pdf"],
    accept_multiple_files=True
)

if uploaded_files:
    for file in uploaded_files:
        file_path = os.path.join(PDF_DIR, file.name)
        with open(file_path, "wb") as f:
            f.write(file.getbuffer())
    st.sidebar.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")

# =======================
# Load LLM
# =======================
llm = ChatGroq(
    model="openai/gpt-oss-20b",
    groq_api_key=GROQ_API_KEY,
    temperature=0
)

# =======================
# Load & Index PDFs
# =======================
@st.cache_resource
def load_vectorstore():
    loader = PyPDFDirectoryLoader(PDF_DIR)
    documents = loader.load()

    if len(documents) == 0:
        return None

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150
    )
    docs = splitter.split_documents(documents)

    if len(docs) == 0:
        return None

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    return FAISS.from_documents(docs, embeddings)

# Clear cache if new files uploaded
if uploaded_files:
    st.cache_resource.clear()

vectorstore = load_vectorstore()

if vectorstore is None:
    st.info("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¨Ø¯Ø¡")
    st.stop()

retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# =======================
# Prompt
# =======================
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø­ØªØ±Ù ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ† ÙÙ‚Ø·.

Ø­Ù„Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…ØªØ§Ø­ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§.
Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙÙƒÙŠØ± Ø£Ùˆ Ø®Ø·ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„.
Ø£Ø®Ø±Ø¬ ÙÙ‚Ø· Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù….

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
- Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©
- Ù…Ù„Ø®Øµ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¯Ù‚ÙŠÙ‚
- Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· ÙˆÙˆØ§Ø¶Ø­

Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:
{context}

Ø§Ù„Ø³Ø¤Ø§Ù„:
{question}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""
)

# =======================
# RAG Chain
# =======================
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
)

# =======================
# UI â€“ Ask Question
# =======================
query = st.text_input(
    "ğŸ“ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ:",
    placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ØªØ²ÙˆÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ø±Ø§Øª Ø§Ù„Ø±Ø³Ù…ÙŠØ©ØŸ"
)

if st.button("ğŸ” Ø§Ø³Ø£Ù„"):
    if not query.strip():
        st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ")
    else:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†..."):
            response = rag_chain.invoke(query)
            source_docs = retriever.invoke(query)

        st.subheader("ğŸ“Œ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©")
        st.write(response.content)

        with st.expander("ğŸ“„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"):
            for doc in source_docs:
                st.markdown(
                    f"**ØµÙØ­Ø©:** {doc.metadata.get('page', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}"
                )





